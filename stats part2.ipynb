{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64245296-ab67-4b8d-8217-1a6c8c75e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#1. What is hypothesis testing in statistics\n",
    "A.Hypothesis testing is a fundamental statistical method used to make inferences about a population based on sample data.\n",
    "It helps determine whether there is enough evidence to support a specific claim or assumption about a population parameter.\n",
    "\n",
    "#2.What is the null hypothesis, and how does it differ from the alternative hypothesis\n",
    "A. Null Hypothesis (H‚ÇÄ)\n",
    "Definition: The default assumption that there is no effect, no difference, or no relationship in the population ‚Äî\n",
    "any observed result is due to chance.\n",
    "Alternative Hypothesis (H‚Çê or H‚ÇÅ)\n",
    "Definition: The hypothesis you want to investigate‚Äîclaims that there is an effect, difference, or relationship in the population\n",
    " \n",
    "#3.What is the significance level in hypothesis testing, and why is it important\n",
    "A.he significance level, denoted by Œ± (alpha), is a preset threshold that defines how much risk of making a Type I error (a false positive) \n",
    "you're willing to accept in a hypothesis test. \n",
    "In essence, it‚Äôs the maximum probability you're okay with of rejecting the null hypothesis when it is actually true\n",
    " \n",
    "#4.What does a P-value represent in hypothesis testing\n",
    "A.A p‚Äëvalue is the probability of observing data at least as extreme as what you collected, assuming the null hypothesis (H‚ÇÄ) is true.\n",
    "\n",
    "#5.How do you interpret the P-value in hypothesis testing\n",
    "| p-value range  | Interpretation                                        |\n",
    "| -------------- | ----------------------------------------------------- |\n",
    "| p ‚â§ Œ±          | Data unlikely if H‚ÇÄ is true; **reject H‚ÇÄ**            |\n",
    "| p just below Œ± | Marginal significance ‚Äî evidence is **weak/moderate** |\n",
    "| p ‚â™ Œ±          | Very unlikely under H‚ÇÄ; **strong evidence** for H‚ÇÅ    |\n",
    "| p > Œ±          | Data compatible with H‚ÇÄ; **fail to reject H‚ÇÄ**        |\n",
    "\n",
    "\n",
    " #6.What are Type 1 and Type 2 errors in hypothesis testing\n",
    " A.Type‚ÄØI (Œ±) = false alarm ‚Äî you see an effect that isn‚Äôt real.\n",
    "Type‚ÄØII (Œ≤) = missed detection ‚Äî you don‚Äôt see an effect that is there.\n",
    "The balance between them is crucial and depends on how costly each error is in your situation.\n",
    "\n",
    "#7.What is the difference between a one-tailed and a two-tailed test in hypothesis testing\n",
    "| Feature                    | One‚ÄëTailed Test                           | Two‚ÄëTailed Test                           |\n",
    "| -------------------------- | ----------------------------------------- | ----------------------------------------- |\n",
    "| **Alternative Hypothesis** | Directional (greater or less)             | Non‚Äëdirectional (‚â†)                       |\n",
    "| **Critical region**        | Entire Œ± in **one** tail                  | Œ± split into **both** tails (Œ±/2 each)    |\n",
    "| **Power**                  | **Higher** for detecting in one direction | Lower per direction, but global detection |\n",
    "| **Risk**                   | **Misses** opposite-direction effects     | Biased towards either direction           |\n",
    "\n",
    "\n",
    "#8.What is the Z-test, and when is it used in hypothesis testing\n",
    "A.A Z‚Äëtest is a type of hypothesis test where the test statistic follows a standard normal (Z) distribution under the null hypothesis \n",
    "It‚Äôs commonly used to determine whether a sample mean (or proportion) significantly differs from a known population mean (or proportion) .\n",
    "Use a Z‚Äëtest when:\n",
    "Population standard deviation (œÉ) is known, AND\n",
    "The sample size is large (typically ùëõ‚â•30), ensuring approximate normality via the central limit theorem\n",
    " \n",
    "#9.How do you calculate the Z-score, and what does it represent in hypothesis testing\n",
    "A.what the Z-score Represents\n",
    "Standardized distance between your sample result and the null hypothesis mean.\n",
    "Measures how many standard deviations (or standard errors) away your result lies from expectation\n",
    "\n",
    "#10.What is the T-distribution, and when should it be used instead of the normal distribution?\n",
    "A.The Student‚Äôs t-distribution is a probability distribution used in place of the standard normal (Z) distribution\n",
    "when the population standard deviation (œÉ) is unknown and typically when dealing with small samples. \n",
    "It's central to hypothesis testing (t‚Äëtests) and constructing confidence intervals.\n",
    "Use the t‚Äëdistribution when:\n",
    "The population standard deviation is unknown, and you estimate it using the sample standard deviation (s) \n",
    "The sample size is small, typically n < 30, though the line blurs as n grows \n",
    "You have reason to believe the underlying population is normal‚Äîor at least not extremely non-normal‚Äî\n",
    "which ensures validity for small samples\n",
    "\n",
    "#11.What is the difference between a Z-test and a T-test?\n",
    "| Feature                | Z-test                                               | T-test                                         |\n",
    "| ---------------------- | ---------------------------------------------------- | ---------------------------------------------- |\n",
    "| **œÉ known?**           | Yes                                                |  No (uses sample s)                           |\n",
    "| **Sample size**        | Usually ‚â•30 (large)                                  | Ideal <30 (small)                              |\n",
    "| **Test statistic**     | Standard normal $Z$                                  | Student‚Äôs t (df = n‚Äì1, or more)                |\n",
    "| **Distribution tails** | Lighter tails                                        | Heavier tails‚Äîadjusts for variance uncertainty |\n",
    "| **Proportions?**       | Yes (Z‚Äëproportion test) ([DataCamp][1], [Reddit][2]) | No                                             |\n",
    "\n",
    "\n",
    "#12.What is the T-test, and how is it used in hypothesis testing\n",
    "A.A t-test (widely known as Student‚Äôs t-test) is a statistical method used to compare means‚Äîeither against a \n",
    "known value or between two groups‚Äîto determineif observed differences are statistically significant \n",
    "It‚Äôs used when the population standard deviation (œÉ) is unknown and typically when the sample size is small, \n",
    "relying on the t-distribution, which has heavier tails to account for extra uncertainty .\n",
    " \n",
    "#13.What is the relationship between Z-test and T-test in hypothesis testing\n",
    "| Feature                | Z-Test                     | T-Test                                     |\n",
    "| ---------------------- | -------------------------- | ------------------------------------------ |\n",
    "| **œÉ known?**           |  Yes                      | No (uses s)                              |\n",
    "| **Test statistic**     | Z \\~ N(0,‚ÄØ1)               | t \\~ Student‚Äôs t(df‚ÄØ‚âà‚ÄØn‚ÄØ‚àí‚ÄØ1)               |\n",
    "| **Distribution shape** | Fixed                      | Depends on df (heavier tails with small n) |\n",
    "| **Sample size**        | Large (often‚ÄØn‚ÄØ‚â•‚ÄØ30‚Äì50)    | Any, especially small n                    |\n",
    "| **Accuracy**           | Approximate when œÉ unknown | Exact under normality                      |\n",
    "| **Convergence**        | ‚Äî                          | t ‚Üí N as n increases                       |\n",
    "\n",
    "#14.What is a confidence interval, and how is it used to interpret statistical results\n",
    "A.A confidence interval (CI) is a range of values, constructed from sample data, that‚Äôs likely to contain an\n",
    "unknown population parameter (such as a mean or proportion).\n",
    "It reflects not only your best estimate (the sample statistic) but also the uncertainty around it.\n",
    "Interpreting an Interval\n",
    "If a survey yields a 95% CI for average exam score of [70, 80], you can say:\n",
    "‚ÄúWe are 95% confident that the true population average score lies between 70 and 80.‚Äù\n",
    "This means the method used captures the true mean 95% of the time across repeated samples\n",
    " \n",
    "#15.What is the margin of error, and how does it affect the confidence interval\n",
    "A.he MOE is the amount added and subtracted from your sample estimate to form a confidence interval;\n",
    "essentially,it‚Äôs half the interval width.\n",
    "How MOE Affects the Confidence Interval\n",
    "Width of the CI = sample estimate ¬± MOE ‚Üí larger MOE ‚Üí wider CI .\n",
    "Narrower MOE (more precision) occurs when:\n",
    "Sample size (n) is larger ‚Üí SE decreases ‚Üí MOE shrinks \n",
    "confidence level is lower (e.g., 90% vs 95%) ‚Üí smaller critical value ‚Üí narrower CI \n",
    "Variability (œÉ or p(1‚Äìp)) is smaller ‚Üí SE is smaller ‚Üí MOE is smaller .\n",
    "Trade-off: higher confidence ‚Üí wider margin (e.g., 99% CI > 95% CI) \n",
    "\n",
    "#16.How is Bayes' Theorem used in statistics, and what is its significance\n",
    "A.Bayes‚Äô Theorem offers a rational, probabilistic way to update beliefs based on new data and existing knowledge. \n",
    "It underlies Bayesian statistics, decision-making under uncertainty, and modern AI systems. By combining priors, likelihoods, and evolving evidence, Bayes allows us to arrive at more accurate, realistic conclusions than traditional approaches\n",
    "\n",
    "#17.What is the Chi-square distribution, and when is it used?\n",
    "A.Chi-square distribution arises from sums of squared normal variables and is essential for evaluating categorical data.\n",
    "It‚Äôs the backbone of key statistical tests like goodness-of-fit and test of independence, plus variance-based methods.\n",
    "You use it to check how well observed data match expectations or to uncover relationships between categories.\n",
    " \n",
    "#18.What is the Chi-square goodness of fit test, and how is it applied?\n",
    "A.The Chi‚Äësquare (œá¬≤) goodness‚Äëof‚Äëfit test is a statistical method used to assess whether observed categorical data match a\n",
    "theoretical distribution of expected frequencies.\n",
    "How to use?\n",
    "State the hypotheses:\n",
    "H‚ÇÄ: Observed distribution matches the expected proportions.\n",
    "H‚ÇÅ: Observed distribution differs from expected \n",
    "Calculate expected frequencies for each category (e.g., total sample √ó expected proportion) \n",
    "Compute the œá¬≤ statistic using:ùúí2=‚àë(ùëÇ‚àíùê∏)/2.where O is observed count and E is expected count \n",
    "Determine degrees of freedom (df):For a goodness-of-fit test: df = number of categories ‚Äì 1 .\n",
    "Compare the calculated œá¬≤ to the critical value (based on df and chosen significance level) or\n",
    "derive a p-value from the œá¬≤ distribution.\n",
    "Draw conclusions:\n",
    "If œá¬≤ is greater than the critical value (or p ‚â§ Œ±), reject H‚ÇÄ‚Äîthe data likely do not fit the expected distribution.\n",
    "If œá¬≤ is smaller, fail to reject H‚ÇÄ‚Äîno evidence of a difference.\n",
    "\n",
    "#19.What is the F-distribution, and when is it used in hypothesis testing?\n",
    "The F‚Äëdistribution, also called the Fisher‚ÄìSnedecor distribution, is a continuous probability distribution used to model\n",
    "the ratio of two independent chi-square variables, each divided by its respective degrees of freedom. It is right-skewed,\n",
    "defined only for positive values, and its shape depends on two degrees of freedom: numerator (df‚ÇÅ) and denominator (df‚ÇÇ).\n",
    "Use Case;\n",
    "1. Testing Equality of Variances\n",
    "2.ANOVA (Analysis of Variance)\n",
    "3. Model Comparison in Regression\n",
    " \n",
    " #20.What is an ANOVA test, and what are its assumptions\n",
    " A.ANOVA is a statistical method for comparing the means of three or more groups simultaneously‚Äîto determine whether at least one group\n",
    " mean differssignificantly from the others. It achieves this by comparing the between-group variance to the within-group variance,u\n",
    " sing an F-statistic derived from the F-distribution\n",
    " \n",
    "#21.What are the different types of ANOVA tests?\n",
    "A.One-way ANOVA involves a single categorical factor (e.g., comparing test scores among 3 teaching methods) \n",
    "Two-way ANOVA or factorial ANOVA involves two categorical factors and can assess interaction effects .\n",
    "\n",
    "#22.What is the F-test, and how does it relate to hypothesis testing?\n",
    "A.The F-test is a broad category of statistical tests that use the F-statistic‚Äîa ratio that follows the F-distribution‚Äîto assess \n",
    "differences in variances, model fits, or group means. \n",
    " In Hypothesis Testing\n",
    "The F-test provides a way to quantify and test whether two variances, multiple means, or \n",
    "model fits differ more than would be expected by chance.\n",
    "It's flexible: used for variance comparison, ANOVA, regression evaluation, nested model tests, and more\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a668186-d01a-4561-9199-f0c812d19f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practical Part - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343e6c14-2964-4d6d-9961-6021fa922323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random value: 0.8178110711260915\n"
     ]
    }
   ],
   "source": [
    "#1. Write a Python program to generate a random variable and display its value?\n",
    "import random\n",
    "value = random.random()\n",
    "print(\"Random value:\", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3710504-afbf-457a-a76a-3e79c75891b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Generate a discrete uniform distribution using Python and plot the probability mass function (PMF)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define discrete uniform distribution: integers 1 through 6 (like a fair die)\n",
    "low, high = 1, 7  # scipy's randint uses half-open [low, high)\n",
    "dist = randint(low, high)\n",
    "\n",
    "# Possible outcomes and their PMF values\n",
    "x = np.arange(low, high)\n",
    "pmf = dist.pmf(x)\n",
    "\n",
    "# Simulate random draws\n",
    "np.random.seed(0)\n",
    "data = dist.rvs(size=1000)\n",
    "\n",
    "# Plot PMF\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(x, pmf, width=0.6, alpha=0.7, edgecolor='black', label='Theoretical PMF')\n",
    "# Overlay empirical frequencies\n",
    "counts = np.bincount(data - low, minlength=high - low)\n",
    "emp_pmf = counts / counts.sum()\n",
    "plt.scatter(x, emp_pmf, color='red', label='Empirical PMF (1000 draws)')\n",
    "plt.xticks(x)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Discrete Uniform Distribution PMF (1‚Äì6)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658f79e-4f50-4f00-a18f-727a852249e9",
   "metadata": {},
   "source": [
    "#3. Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution\n",
    "def bernoulli_pmf(k, p):\n",
    "    \"\"\"\n",
    "    PMF of a Bernoulli random variable:\n",
    "    P(X = k) = p     if k=1\n",
    "               1-p   if k=0\n",
    "               0     otherwise\n",
    "    \"\"\"\n",
    "    return p if k == 1 else (1 - p if k == 0 else 0)\n",
    "\n",
    "p = 0.3  # probability of success\n",
    "print(\"P(X=1):\", bernoulli_pmf(1, p))  # returns 0.3\n",
    "print(\"P(X=0):\", bernoulli_pmf(0, p))  # returns 0.7\n",
    "print(\"P(X=2):\", bernoulli_pmf(2, p))  # returns 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67749ad4-cced-464e-9201-7e9668392e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.44444444444444444444444444444444444444444444444444444444444444444444444444444Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8f538-b454-48d2-96d0-2f3224b256c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df5bf8-1cd8-447b-a592-3563c74fad3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7143add-e401-4e65-90ab-afafd8a28d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1259580-ce3d-4dc5-a102-08067968bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe2829-1814-4a24-974e-a0bf69138255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c560db-5c3c-4727-bc0c-bab4a5044768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c197f6-9543-4708-8006-e6db711f860e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fde991-27ab-4e20-acfd-b9444c0a6583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cab9ce-4ca3-4297-946e-9f2bd8f4dfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620c832-c4ed-407f-8df3-3ea7cb7a54e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9d623-a12d-4590-b8a6-4bae40eebd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29445bc2-90de-4843-a754-5155e9ef346d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5a6e7-a264-4c83-96df-2d3ee88f18aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be619b8-3199-45bd-b06c-c20099844d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345598d-bbb6-431c-89db-a12f777ceabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cff862-f087-4ba7-9f52-50b38f2d8425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c31984-2d31-499c-8a5d-ca354f0e9693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb2d7b-2992-4a04-8a0b-826f12187843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "n, p, size = 10, 0.5, 10000\n",
    "\n",
    "# Simulate binomial random variables\n",
    "data = np.random.binomial(n=n, p=p, size=size)\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(data, bins=range(n+2), align='left', rwidth=0.8, density=True, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Overlay theoretical probabilities\n",
    "from scipy.stats import binom\n",
    "x = np.arange(0, n + 1)\n",
    "pmf = binom.pmf(x, n, p)\n",
    "plt.plot(x, pmf, 'ro-', label='Theoretical PMF')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Number of Successes')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Binomial Distribution (n={n}, p={p})')\n",
    "plt.xticks(x)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9396eaf-2b9b-49e9-9b08-ff9ea7091532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Create a Poisson distribution and visualize it using Python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "\n",
    "#  Parameters\n",
    "mu = 4       # average event rate Œª\n",
    "size = 10000\n",
    "\n",
    "# Generate Poisson random samples\n",
    "data = poisson.rvs(mu=mu, size=size)\n",
    "\n",
    "# Create histogram of the sampled data\n",
    "plt.figure(figsize=(8, 4))\n",
    "bins = np.arange(data.min(), data.max()+2) - 0.5\n",
    "plt.hist(data, bins=bins, density=True, edgecolor='black', alpha=0.7, label='Simulated')\n",
    "\n",
    "# Overlay theoretical PMF\n",
    "x = np.arange(data.min(), data.max()+1)\n",
    "pmf = poisson.pmf(x, mu)\n",
    "plt.plot(x, pmf, 'ro-', label='Theoretical PMF')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Event count (k)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Poisson Distribution (Œª = {mu})')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206dd245-2f2d-46be-a48f-d6a689516e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Parameters\n",
    "a, b = 1, 6  # inclusive range\n",
    "dist = randint(a, b + 1)  # scipy uses [a, b+1) :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "# Support and CDF\n",
    "x = np.arange(a, b + 1)\n",
    "cdf_vals = dist.cdf(x)\n",
    "\n",
    "# Plot CDF as a step function\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.step(x, cdf_vals, where='post', label='Theoretical CDF', color='blue')\n",
    "plt.scatter(x, cdf_vals, color='red')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('P(X ‚â§ k)')\n",
    "plt.title(f'Cumulative Distribution Function\\nDiscrete Uniform U({a},{b})')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48b017-d830-44fe-84ce-b3177ed3a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.Generate a continuous uniform distribution using NumPy and visualize it\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Parameters\n",
    "low, high = 2.0, 5.0\n",
    "size = 10000\n",
    "\n",
    "# Generate random samples\n",
    "data = np.random.uniform(low=low, high=high, size=size)  # NumPy's uniform draws from [low, high) :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "# Plot histogram (normalized to density)\n",
    "plt.figure(figsize=(8,4))\n",
    "count, bins, _ = plt.hist(data, bins=30, density=True, edgecolor='black', alpha=0.7, label='Simulated samples')\n",
    "\n",
    "# Theoretical PDF overlay\n",
    "x = np.linspace(low, high, 200)\n",
    "pdf = uniform.pdf(x, loc=low, scale=high-low)  # SciPy‚Äôs uniform.pdf on [loc, loc+scale] :contentReference[oaicite:2]{index=2}\n",
    "plt.plot(x, pdf, 'r-', lw=2, label='Theoretical PDF')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Continuous Uniform Distribution PDF [{low}, {high})')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4957a1e-64ea-4a9f-b3fb-2ab2172ac694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Simulate data from a normal distribution and plot its histogram?\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Parameters\n",
    "mu, sigma = 0, 1  # mean and standard deviation\n",
    "N = 100000        # number of samples\n",
    "\n",
    "# Simulate normal random samples\n",
    "data = np.random.randn(N)  # standard normal; same as np.random.normal(mu, sigma, N)\n",
    "# Or: data = np.random.normal(mu, sigma, N)\n",
    "\n",
    "# Plot histogram (normalized to form a density)\n",
    "plt.figure(figsize=(8, 5))\n",
    "count, bins, _ = plt.hist(data, bins=50, density=True, alpha=0.6, color='skyblue', edgecolor='black', label='Simulated data')\n",
    "\n",
    "# Overlay the theoretical normal PDF\n",
    "x = np.linspace(bins.min(), bins.max(), 200)\n",
    "pdf = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, pdf, 'r-', lw=2, label='Theoretical PDF')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Histogram of Simulated Normal Data (Œº={mu}, œÉ={sigma})')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b2aef8-f77e-4fb6-b2b7-4b0ae79ffd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Write a Python function to calculate Z-scores from a dataset and plot them\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def compute_z_scores(data):\n",
    "    \"\"\"\n",
    "    Compute z-scores for a 1D dataset.\n",
    "\n",
    "    Z = (X - mean) / std_dev\n",
    "    \"\"\"\n",
    "    data = np.asarray(data)\n",
    "    return (data - data.mean()) / data.std(ddof=0)\n",
    "\n",
    "# Example dataset\n",
    "data = [10, 20, 30, 40, 50, 100]  # Notice the outlier at 100\n",
    "\n",
    "# Compute z-scores manually\n",
    "zs_manual = compute_z_scores(data)\n",
    "\n",
    "# Or use SciPy (handles NaNs etc.)\n",
    "zs_scipy = zscore(data, ddof=0)\n",
    "\n",
    "print(\"Manual z-scores:\", zs_manual)\n",
    "print(\"SciPy z-scores :\", zs_scipy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0258fa5-7522-4f15-9c49-ddff86025242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution?\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Population: Exponential (non-normal), Œª=1\n",
    "population = np.random.exponential(scale=1.0, size=100000)\n",
    "\n",
    "def sample_means(pop, sample_size, num_samples=5000):\n",
    "    return [np.mean(np.random.choice(pop, sample_size, replace=True))\n",
    "            for _ in range(num_samples)]\n",
    "\n",
    "# Choose sample sizes to illustrate CLT\n",
    "sample_sizes = [1, 5, 30, 100]\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, n in enumerate(sample_sizes, 1):\n",
    "    means = sample_means(population, n)\n",
    "\n",
    "    ax = plt.subplot(2, 2, i)\n",
    "    ax.hist(means, bins=30, density=True, alpha=0.6,\n",
    "            color='skyblue', edgecolor='black')\n",
    "    \n",
    "    # Overlay normal curve\n",
    "    mu, sigma = np.mean(means), np.std(means)\n",
    "    x = np.linspace(min(means), max(means), 200)\n",
    "    ax.plot(x, norm.pdf(x, mu, sigma), 'r-', lw=2)\n",
    "    \n",
    "    ax.set_title(f'Sample size = {n}')\n",
    "    ax.set_xlabel('Sample mean')\n",
    "    ax.set_ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b038be-f5da-40b4-9dd8-a875fe07fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.Simulate multiple samples from a normal distribution and verify the Central Limit Theorem\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Population parameters (true normal distribution)\n",
    "mu, sigma = 5, 2\n",
    "population_size = 1000000\n",
    "population = np.random.normal(loc=mu, scale=sigma, size=population_size)\n",
    "\n",
    "# Simulation parameters\n",
    "sample_sizes = [5, 20, 50, 100]\n",
    "num_samples = 5000\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, n in enumerate(sample_sizes, 1):\n",
    "    # Draw many samples of size n, compute their means\n",
    "    means = [np.mean(np.random.choice(population, size=n, replace=False))\n",
    "             for _ in range(num_samples)]\n",
    "    \n",
    "    ax = plt.subplot(2, 2, i)\n",
    "    ax.hist(means, bins=30, density=True, alpha=0.6, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Overlay theoretical normal curve: expected distribution of sample means\n",
    "    theoretical_mu = mu\n",
    "    theoretical_sigma = sigma / np.sqrt(n)\n",
    "    x = np.linspace(min(means), max(means), 200)\n",
    "    ax.plot(x, norm.pdf(x, theoretical_mu, theoretical_sigma), 'r--', lw=2)\n",
    "\n",
    "    ax.set_title(f'sample size = {n}')\n",
    "    ax.set_xlabel('Sample mean')\n",
    "    ax.set_ylabel('Density')\n",
    "\n",
    "plt.suptitle('CLT Verified: Distribution of Sample Means (Normal Population)')\n",
    "plt.tight_layout(rect=[0,0.03,1,0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86081f-30e1-4e82-b395-4464bd56160d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #12.Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "def plot_standard_normal(x_min=-4, x_max=4, num_points=1000):\n",
    "    \"\"\"\n",
    "    Plots the standard normal distribution PDF (mean=0, std=1)\n",
    "    over a specified range [x_min, x_max].\n",
    "    \"\"\"\n",
    "    x = np.linspace(x_min, x_max, num_points)\n",
    "    pdf = norm.pdf(x, loc=0, scale=1)  # standard normal PDF\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(x, pdf, 'b-', label='Standard Normal PDF')\n",
    "    plt.axhline(0, color='black', linewidth=0.5)\n",
    "    plt.xlabel('z')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title('Standard Normal Distribution (Œº=0, œÉ=1)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_standard_normal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a612aaf-c6ba-480a-a77b-8ea64b07e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. Generate random variables and calculate their corresponding probabilities using the binomial distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "\n",
    "def simulate_binomial(n, p, num_samples=10000):\n",
    "    # Generate binomial random variables\n",
    "    data = np.random.binomial(n=n, p=p, size=num_samples)\n",
    "    \n",
    "    # Unique outcomes and their empirical probabilities\n",
    "    values, counts = np.unique(data, return_counts=True)\n",
    "    emp_pmf = counts / num_samples\n",
    "    \n",
    "    # Theoretical PMF for all possible outcomes\n",
    "    k = np.arange(0, n + 1)\n",
    "    theo_pmf = binom.pmf(k, n, p)\n",
    "    \n",
    "    return values, emp_pmf, k, theo_pmf\n",
    "\n",
    "# Example parameters\n",
    "n, p = 10, 0.3\n",
    "values, emp_pmf, k, theo_pmf = simulate_binomial(n, p)\n",
    "\n",
    "# Plotting both empirical and theoretical PMFs\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(values, emp_pmf, width=0.4, label='Empirical PMF', alpha=0.7, align='center')\n",
    "plt.plot(k, theo_pmf, 'ro-', label='Theoretical PMF')\n",
    "plt.xlabel('Number of Successes')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(f'Binomial Distribution (n={n}, p={p})')\n",
    "plt.xticks(k)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c335c5b-611d-4975-9eb8-4012b016c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #14.Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, zscore\n",
    "\n",
    "def compute_z_score(x, data):\n",
    "    \"\"\"\n",
    "    Compute the z-score of x relative to the dataset:\n",
    "        z = (x ‚àí mean) / std_dev\n",
    "    \"\"\"\n",
    "    mu = np.mean(data)\n",
    "    sigma = np.std(data, ddof=0)\n",
    "    return (x - mu) / sigma\n",
    "\n",
    "# Example dataset and target value\n",
    "data = np.random.normal(loc=50, scale=5, size=1000)\n",
    "x_value = 58\n",
    "\n",
    "# Calculate z-score manually and via SciPy\n",
    "z_manual = compute_z_score(x_value, data)\n",
    "z_scipy = zscore(np.array([x_value] + list(data)))[0]  # first element corresponds to x_value\n",
    "\n",
    "# Compute cumulative probability\n",
    "p = norm.cdf(z_manual)\n",
    "\n",
    "print(f\"Manual z-score for x={x_value}: {z_manual:.3f}\")\n",
    "print(f\"SciPy-based z-score       : {z_scipy:.3f}\")\n",
    "print(f\"P(Z ‚â§ {z_manual:.3f})     = {p:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "x = np.linspace(-4, 4, 400)\n",
    "y = norm.pdf(x)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(x, y, 'b-', label='Standard Normal PDF')\n",
    "plt.fill_between(x, y, where=(x <= z_manual), color='skyblue', alpha=0.5, label=f'P(Z ‚â§ {z_manual:.2f})')\n",
    "plt.axvline(z_manual, color='red', linestyle='--', lw=2, label=f'z = {z_manual:.2f}')\n",
    "\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Z‚Äëscore on Standard Normal Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4156d22-e7c6-445b-a2f8-ee8461b2709a",
   "metadata": {},
   "outputs": [],
   "source": [
    " #15.Implement hypothesis testing using Z-statistics for a sample dataset\n",
    "import numpy as np\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Sample dataset (e.g., exam scores)\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=105, scale=10, size=50)  # mean‚âà105, œÉ‚âà10\n",
    "\n",
    "# Known population mean and SD (assumed known)\n",
    "pop_mean = 100\n",
    "pop_std = 10  # known œÉ\n",
    "n = len(data)\n",
    "\n",
    "# Compute sample mean\n",
    "sample_mean = data.mean()\n",
    "\n",
    "# Manually compute the Z-statistic:\n",
    "z_manual = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
    "\n",
    "# One-sample Z-test using statsmodels:\n",
    "z_stat, p_value = ztest(data, value=pop_mean)\n",
    "\n",
    "print(f\"Sample mean: {sample_mean:.2f}\")\n",
    "print(f\"Manual Z-statistic: {z_manual:.3f}\")\n",
    "print(f\"Statsmodels Z-statistic: {z_stat:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Critical value at Œ±=0.05 (two-tailed):\n",
    "z_crit = norm.ppf(1 - 0.05 / 2)\n",
    "print(f\"Critical Z-value (¬±): {z_crit:.3f}\")\n",
    "\n",
    "# Decision\n",
    "if abs(z_stat) > z_crit:\n",
    "    print(\"‚Üí Reject H‚ÇÄ: sample mean is significantly different.\")\n",
    "else:\n",
    "    print(\"‚Üí Fail to reject H‚ÇÄ: no significant difference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cc8fb-6989-47ae-91cd-c26fe33a033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16. Create a confidence interval for a dataset using Python and interpret the result\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example dataset (e.g., exam scores)\n",
    "data = np.array([78, 85, 92, 70, 88, 95, 80, 75, 90, 85])\n",
    "\n",
    "# Compute sample statistics\n",
    "n = len(data)\n",
    "mean = data.mean()\n",
    "sem = stats.sem(data)  # standard error of mean = s / sqrt(n)\n",
    "\n",
    "# Build 95% confidence interval using t-distribution\n",
    "confidence = 0.95\n",
    "ci_lower, ci_upper = stats.t.interval(confidence, df=n-1, loc=mean, scale=sem)\n",
    "\n",
    "print(f\"Sample mean: {mean:.2f}\")\n",
    "print(f\"95% confidence interval: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc76fc-2aac-4ac9-a780-8ab27b826ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17.Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# 1. Simulate data\n",
    "np.random.seed(42)\n",
    "mu_true, sigma_true, n = 100, 15, 50\n",
    "data = np.random.normal(loc=mu_true, scale=sigma_true, size=n)\n",
    "\n",
    "# 2. Compute sample statistics\n",
    "sample_mean = np.mean(data)\n",
    "sem = stats.sem(data)  # standard error = s / sqrt(n)\n",
    "\n",
    "# 3. Build 95% CI using t-distribution\n",
    "alpha = 0.05\n",
    "ci_lower, ci_upper = stats.t.interval(alpha=1-alpha, df=n-1, loc=sample_mean, scale=sem)\n",
    "\n",
    "print(f\"Sample mean: {sample_mean:.2f}\")\n",
    "print(f\"95% CI for population mean: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12714c40-9d95-41f2-a83d-f25abac6b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "def plot_normal_pdf(mu=0, sigma=1, x_min=-4, x_max=4, num_points=1000):\n",
    "    \"\"\"\n",
    "    Plot the normal distribution PDF with given mean (mu) and standard deviation (sigma).\n",
    "    \"\"\"\n",
    "    x = np.linspace(x_min, x_max, num_points)\n",
    "    y = norm.pdf(x, loc=mu, scale=sigma)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(x, y, 'b-', lw=2, label=f'N({mu}, {sigma}¬≤)')\n",
    "    plt.fill_between(x, y, alpha=0.2)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title('Normal Distribution PDF')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_normal_pdf(mu=5, sigma=2, x_min=-1, x_max=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a7216-31a7-47fe-bb6a-e539f42dcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19.Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Parameters\n",
    "mu = 4  # average event rate Œª\n",
    "\n",
    "# Possible outcomes (k values)\n",
    "k = np.arange(0, 15)\n",
    "\n",
    "# Compute Poisson CDF values\n",
    "cdf_vals = poisson.cdf(k, mu=mu)\n",
    "\n",
    "# Display probabilities: P(X ‚â§ k)\n",
    "for ki, ci in zip(k, cdf_vals):\n",
    "    print(f\"P(X ‚â§ {ki}) = {ci:.4f}\")\n",
    "\n",
    "# Plot the CDF\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.step(k, cdf_vals, where='post', label='Poisson CDF')\n",
    "plt.scatter(k, cdf_vals, color='red')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('F(k) = P(X ‚â§ k)')\n",
    "plt.title(f'Cumulative Distribution Function of Poisson(Œª={mu})')\n",
    "plt.ylim(-0.03, 1.03)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcd2d0-786c-42ed-b11f-8f8ab2f6e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20.Simulate a random variable using a continuous uniform distribution and calculate its expected value\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the uniform distribution\n",
    "a, b = 2.0, 8.0      # minimum and maximum values\n",
    "N = 100_0000         # number of samples\n",
    "\n",
    "# 1. Generate uniform random samples\n",
    "data = np.random.uniform(low=a, high=b, size=N)\n",
    "\n",
    "# 2. Compute the empirical expected value (sample mean)\n",
    "emp_mean = data.mean()\n",
    "\n",
    "# 3. Compute the theoretical expected value\n",
    "theoretical_mean = (a + b) / 2\n",
    "\n",
    "print(f\"Empirical mean (from simulation): {emp_mean:.4f}\")\n",
    "print(f\"Theoretical mean E[X] = (a + b)/2      : {theoretical_mean:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b9709-cf81-46a8-b88e-bcfb2ff855e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21. Write a Python program to compare the standard deviations of two datasets and visualize the difference\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "# Example datasets\n",
    "data1 = np.array([36, 37, 36, 34, 39, 33, 30, 30, 32, 31, 31, 32, 32, 33, 35])\n",
    "data2 = np.array([41, 35, 28, 29, 25, 36, 36, 32, 38, 40, 40, 34, 31, 28, 30])\n",
    "\n",
    "# Compute means and standard deviations\n",
    "mean1, std1 = np.mean(data1), np.std(data1, ddof=0)\n",
    "mean2, std2 = np.mean(data2), np.std(data2, ddof=0)\n",
    "\n",
    "# Using statistics.stdev (sample standard deviation)\n",
    "std1_sample = statistics.stdev(data1)\n",
    "std2_sample = statistics.stdev(data2)\n",
    "\n",
    "print(f\"Dataset 1: mean = {mean1:.2f}, std (pop) = {std1:.2f}, std (sample) = {std1_sample:.2f}\")\n",
    "print(f\"Dataset 2: mean = {mean2:.2f}, std (pop) = {std2:.2f}, std (sample) = {std2_sample:.2f}\")\n",
    "\n",
    "# Visualization: bar chart with error bars = standard deviation\n",
    "labels = ['Dataset 1', 'Dataset 2']\n",
    "means = [mean1, mean2]\n",
    "stds = [std1, std2]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.bar(labels, means, yerr=stds, capsize=8, color=['skyblue', 'lightgreen'], edgecolor='black')\n",
    "plt.ylabel('Mean Value ¬± Std Dev')\n",
    "plt.title('Comparing Means and Standard Deviations\\nwith Error Bars')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab257c8-3ec8-4e7a-8bcd-9b967a18cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    " #22.Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import iqr\n",
    "\n",
    "# 1. Simulate data from a normal distribution\n",
    "np.random.seed(0)\n",
    "mu, sigma, n = 50, 10, 500\n",
    "data = np.random.normal(loc=mu, scale=sigma, size=n)\n",
    "\n",
    "# 2. Compute the range and IQR\n",
    "data_range = data.max() - data.min()\n",
    "data_iqr = iqr(data)  # SciPy's IQR: Q3 - Q1 :contentReference[oaicite:4]{index=4}\n",
    "\n",
    "print(f\"Data Range (max - min): {data_range:.2f}\")\n",
    "print(f\"Interquartile Range (IQR): {data_iqr:.2f}\")\n",
    "\n",
    "# 3. Visualize with histogram and quartile lines\n",
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(data, bins=30, density=True, alpha=0.6, color='skyblue', edgecolor='black')\n",
    "plt.axvline(q1, color='red', linestyle='--', label=f\"Q1 (25%) = {q1:.2f}\")\n",
    "plt.axvline(q3, color='red', linestyle='--', label=f\"Q3 (75%) = {q3:.2f}\")\n",
    "plt.axvline(data.min(), color='green', linestyle=':', label=f\"Min = {data.min():.2f}\")\n",
    "plt.axvline(data.max(), color='green', linestyle=':', label=f\"Max = {data.max():.2f}\")\n",
    "plt.title(\"Histogram of Normally Distributed Data with Range & IQR\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa586fea-92c5-43d4-a78b-dc2fe9c0ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    " #23.Implement Z-score normalization on a dataset and visualize its transformation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def z_score_normalize(data):\n",
    "    \"\"\"\n",
    "    Perform Z-score normalization: (X - mean) / std\n",
    "    Returns the normalized data, plus the original mean and std for interpretation.\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=0)\n",
    "    normalized = (data - mean) / std\n",
    "    return normalized, mean, std\n",
    "\n",
    "# 1. Generate synthetic data (e.g. exam scores)\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=50, scale=15, size=200)\n",
    "\n",
    "# 2. Normalize\n",
    "normalized_data, orig_mean, orig_std = z_score_normalize(data)\n",
    "\n",
    "# 3. Display statistics\n",
    "print(f\"Original Mean = {orig_mean:.2f}, Std Dev = {orig_std:.2f}\")\n",
    "print(f\"Normalized Mean = {np.mean(normalized_data):.2e}, Std Dev = {np.std(normalized_data):.2f}\")\n",
    "\n",
    "# 4. Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Original distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=20, density=True, alpha=0.7, edgecolor='black')\n",
    "plt.title(\"Original Data\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.axvline(orig_mean, color='r', linestyle='--', label=f\"Mean ‚âà {orig_mean:.1f}\")\n",
    "plt.legend()\n",
    "\n",
    "# Normalized distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(normalized_data, bins=20, density=True, alpha=0.7, edgecolor='black')\n",
    "plt.title(\"Z-score Normalized Data\")\n",
    "plt.xlabel(\"Z-score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.axvline(0, color='r', linestyle='--', label=\"Mean = 0\")\n",
    "plt.axvline(1, color='g', linestyle='--', label=\"¬±1 Std Dev\")\n",
    "plt.axvline(-1, color='g', linestyle='--')\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle(\"Effect of Z-score Normalization\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e494dd-6b19-4ebf-aae8-4d79988943f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24. Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis, norm\n",
    "\n",
    "def analyze_skew_kurt(data, fisher=True):\n",
    "    \"\"\"\n",
    "    Compute skewness and kurtosis of a dataset, and plot histogram.\n",
    "    - fisher=True: excess kurtosis (normal ‚Üí 0)\n",
    "    - fisher=False: Pearson's kurtosis (normal ‚Üí 3)\n",
    "    \"\"\"\n",
    "    s = skew(data)\n",
    "    k = kurtosis(data, fisher=fisher)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(data, bins=30, density=True, alpha=0.6, color='lightgray', edgecolor='black')\n",
    "    \n",
    "    # Overlay normal PDF for comparison\n",
    "    mu, sigma = np.mean(data), np.std(data, ddof=0)\n",
    "    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 200)\n",
    "    plt.plot(x, norm.pdf(x, mu, sigma), 'r--', linewidth=2, label='Normal PDF')\n",
    "    \n",
    "    plt.title(f\"Skewness = {s:.3f}, Kurtosis = {k:.3f}\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return s, k\n",
    "\n",
    "# Generate normally distributed data\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Analyze\n",
    "skewness, kurt = analyze_skew_kurt(data)\n",
    "print(f\"Skewness: {skewness:.4f} (‚âà0 for normal)\")\n",
    "print(f\"Excess Kurtosis: {kurt:.4f} (‚âà0 for normal)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0c9cb-feb4-430a-bcd7-ce180e34628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical Part - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4d2ce-6389-4777-a5be-16fcb9a0ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results?\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "# 1. Generate a sample dataset (e.g., test scores)\n",
    "np.random.seed(123)\n",
    "data = np.random.normal(loc=52, scale=10, size=40)  # sample mean ~52, œÉ unknown\n",
    "\n",
    "# 2. Define known population parameters\n",
    "pop_mean = 50     # hypothesized population mean under H‚ÇÄ\n",
    "pop_std = 10      # assumed known population SD\n",
    "n = len(data)\n",
    "\n",
    "# 3. Compute sample mean\n",
    "sample_mean = np.mean(data)\n",
    "\n",
    "# 4. Manual Z-statistic calculation:\n",
    "z_manual = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
    "\n",
    "# 5. Use statsmodels for the z-test:\n",
    "z_stat, p_value = ztest(data, value=pop_mean)\n",
    "\n",
    "# 6. Determine critical values (two-tailed Œ± = 0.05):\n",
    "alpha = 0.05\n",
    "z_crit = norm.ppf(1 - alpha/2)\n",
    "\n",
    "# 7. Output results\n",
    "print(f\"Sample mean        = {sample_mean:.2f}\")\n",
    "print(f\"Manual Z-statistic = {z_manual:.3f}\")\n",
    "print(f\"statsmodels Z      = {z_stat:.3f}\")\n",
    "print(f\"P-value            = {p_value:.4f}\")\n",
    "print(f\"Critical |Z| value = ¬±{z_crit:.3f}\")\n",
    "\n",
    "# 8. Interpretation\n",
    "if abs(z_stat) > z_crit:\n",
    "    print(\"‚Üí Reject H‚ÇÄ: sample mean significantly differs from population mean.\")\n",
    "else:\n",
    "    print(\"‚Üí Fail to reject H‚ÇÄ: insufficient evidence of a difference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e7e33-af2a-49e8-9357-e2659329ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define null hypothesis parameters\n",
    "mu0 = 100      # Null hypothesis mean\n",
    "sigma = 15     # Known population standard deviation\n",
    "n = 30         # Sample size\n",
    "\n",
    "# 2. Draw an observed sample (with a slight true mean shift, e.g., 105)\n",
    "np.random.seed(42)\n",
    "obs = np.random.normal(loc=105, scale=sigma, size=n)\n",
    "obs_mean = obs.mean()\n",
    "z_obs = (obs_mean - mu0) / (sigma / np.sqrt(n))\n",
    "print(f\"Observed mean = {obs_mean:.2f}, Z observed = {z_obs:.3f}\")\n",
    "\n",
    "# 3. Simulate null distribution of Z-scores\n",
    "num_sim = 10000\n",
    "sim_means = np.random.normal(loc=mu0, scale=sigma/np.sqrt(n), size=num_sim)\n",
    "sim_z = (sim_means - mu0) / (sigma / np.sqrt(n))\n",
    "\n",
    "# 4. Estimate two-tailed p-value\n",
    "p_value = np.mean(np.abs(sim_z) >= abs(z_obs))\n",
    "print(f\"Empirical P-value (two-tailed) = {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b2a7a-44b5-4764-8e19-a8fcee32bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "# 1. Generate sample data (mean ~55, œÉ is known)\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=55, scale=10, size=50)  # sample of size n=50\n",
    "\n",
    "# 2. Population parameters\n",
    "pop_mean = 50     # H‚ÇÄ: Œº = pop_mean\n",
    "pop_std = 10      # known œÉ\n",
    "n = len(data)\n",
    "\n",
    "# 3. Compute sample mean and manual Z-statistic\n",
    "sample_mean = np.mean(data)\n",
    "z_manual = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
    "\n",
    "# 4. Use statsmodels' ztest for verification\n",
    "z_stat, p_value = ztest(data, value=pop_mean)\n",
    "\n",
    "# 5. Calculate critical Z for a two-tailed test at Œ±=0.05\n",
    "alpha = 0.05\n",
    "z_crit = norm.ppf(1 - alpha/2)\n",
    "\n",
    "# 6. Results\n",
    "print(f\"Sample mean: {sample_mean:.2f}\")\n",
    "print(f\"Manual Z-statistic: {z_manual:.3f}\")\n",
    "print(f\"statsmodels Z-statistic: {z_stat:.3f}\")\n",
    "print(f\"P-value (two-tailed): {p_value:.4f}\")\n",
    "print(f\"Critical Z-values: ¬±{z_crit:.3f}\")\n",
    "\n",
    "# 7. Interpretation\n",
    "if abs(z_stat) > z_crit:\n",
    "    print(\"‚Üí Reject H‚ÇÄ: sample mean is significantly different from the population mean.\")\n",
    "else:\n",
    "    print(\"‚Üí Fail to reject H‚ÇÄ: no significant difference found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbd2ac-b3a2-416c-9665-2512cc1637e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "# 1. Simulate sample data\n",
    "np.random.seed(123)\n",
    "pop_mean = 100      # Hypothesized mean under H‚ÇÄ\n",
    "pop_std = 15        # Known population standard deviation\n",
    "n = 50\n",
    "data = np.random.normal(loc=105, scale=pop_std, size=n)\n",
    "sample_mean = data.mean()\n",
    "\n",
    "# 2. Compute Z-statistic manually\n",
    "z_manual = (sample_mean - pop_mean) / (pop_std / np.sqrt(n))\n",
    "\n",
    "# 3. Use statsmodels to confirm\n",
    "z_stat, p_value = ztest(data, value=pop_mean)\n",
    "\n",
    "# 4. Define critical values for two-tailed test at Œ± = 0.05\n",
    "alpha = 0.05\n",
    "z_crit = norm.ppf(1 - alpha / 2)  # ‚âà ¬±1.96\n",
    "\n",
    "# 5. Print results\n",
    "print(f\"Sample mean         = {sample_mean:.2f}\")\n",
    "print(f\"Manual Z-statistic  = {z_manual:.3f}\")\n",
    "print(f\"statsmodels Z       = {z_stat:.3f}\")\n",
    "print(f\"P-value (two-tailed)= {p_value:.4f}\")\n",
    "print(f\"Critical Z-values   = ¬±{z_crit:.3f}\")\n",
    "print(\"Decision:\", \"Reject H‚ÇÄ\" if abs(z_stat) > z_crit else \"Fail to reject H‚ÇÄ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f096fbe-bd62-46ee-aaf0-daaa379a657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def simulate_type_errors(pop1, pop2=None, num_tests=1000, alphas=[0.05]):\n",
    "    \"\"\"\n",
    "    Simulate Type I or Type II errors across repeated hypothesis tests.\n",
    "    \n",
    "    - If pop2 is None: performs **Type I** error simulation (two samples from same population).\n",
    "    - If pop2 is provided: performs **Type II** error simulation (samples from different populations).\n",
    "    \n",
    "    Returns:\n",
    "        results: dict mapping alpha ‚Üí (error_rate, p_values array)\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for alpha in alphas:\n",
    "        errors = 0\n",
    "        p_vals = []\n",
    "        for _ in range(num_tests):\n",
    "            sample1 = np.random.choice(pop1, size=100, replace=True)\n",
    "            \n",
    "            if pop2 is None:\n",
    "                sample2 = np.random.choice(pop1, size=100, replace=True)\n",
    "            else:\n",
    "                sample2 = np.random.choice(pop2, size=100, replace=True)\n",
    "\n",
    "            stat, p = ttest_ind(sample1, sample2)\n",
    "            p_vals.append(p)\n",
    "            \n",
    "            if pop2 is None:\n",
    "                # Type I error: reject H0 when true (populations same)\n",
    "                if p < alpha:\n",
    "                    errors += 1\n",
    "            else:\n",
    "                # Type II error: fail to reject H0 when false\n",
    "                if p > alpha:\n",
    "                    errors += 1\n",
    "        \n",
    "        error_rate = errors / num_tests\n",
    "        results[alpha] = (error_rate, np.array(p_vals))\n",
    "    return results\n",
    "\n",
    "# Define populations\n",
    "pop_same = np.random.normal(loc=100, scale=20, size=10000)\n",
    "pop_diff = np.random.normal(loc=110, scale=20, size=10000)\n",
    "\n",
    "alphas = [0.001, 0.01, 0.05, 0.1]\n",
    "res_type1 = simulate_type_errors(pop_same, pop2=None, num_tests=2000, alphas=alphas)\n",
    "res_type2 = simulate_type_errors(pop_same, pop2=pop_diff, num_tests=2000, alphas=alphas)\n",
    "\n",
    "print(\"Type I error rates:\", {a: round(res_type1[a][0],3) for a in alphas})\n",
    "print(\"Type II error rates:\", {a: round(res_type2[a][0],3) for a in alphas})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2e0cb-cc2c-4f73-ad12-e74713474519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.Write a Python program to perform an independent T-test and interpret the results\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Simulate two independent samples\n",
    "np.random.seed(0)\n",
    "group1 = np.random.normal(loc=100, scale=15, size=30)\n",
    "group2 = np.random.normal(loc=110, scale=15, size=30)\n",
    "\n",
    "# 2. Perform Levene‚Äôs test to check equal variances\n",
    "levene_stat, levene_p = stats.levene(group1, group2)\n",
    "\n",
    "# 3. Run the independent t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=(levene_p > 0.05))\n",
    "\n",
    "# 4. Print results\n",
    "print(f\"Group 1 mean = {group1.mean():.2f}, Group 2 mean = {group2.mean():.2f}\")\n",
    "print(f\"Levene‚Äôs test p = {levene_p:.3f} ‚Üí assume equal variances? {'Yes' if levene_p>0.05 else 'No'}\")\n",
    "print(f\"t-statistic = {t_stat:.3f}, p-value = {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bdc23-0ef9-468f-9120-bb3e9a813258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.Perform a paired sample T-test using Python and visualize the comparison results\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# 1. Generate paired sample data (e.g., before/after measurements)\n",
    "np.random.seed(42)\n",
    "pre = np.random.normal(loc=100, scale=10, size=30)\n",
    "post = pre + np.random.normal(loc=5, scale=8, size=30)  # average 5-unit improvement\n",
    "\n",
    "# 2. Perform paired t-test\n",
    "t_stat, p_value = ttest_rel(pre, post)\n",
    "\n",
    "print(f\"t-statistic = {t_stat:.3f}\")\n",
    "print(f\"p-value     = {p_value:.4f}\")\n",
    "\n",
    "# 3. Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"‚Üí Reject H‚ÇÄ: The difference is statistically significant.\")\n",
    "else:\n",
    "    print(\"‚Üí Fail to reject H‚ÇÄ: No significant difference detected.\")\n",
    "\n",
    "# 4. Visualizations\n",
    "diff = post - pre\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# A. Histogram of Differences\n",
    "axes[0].hist(diff, bins=10, density=True, alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(diff.mean(), color='red', linestyle='--',\n",
    "                label=f\"Mean diff = {diff.mean():.2f}\")\n",
    "axes[0].set_title(\"Distribution of Post‚ÄìPre Differences\")\n",
    "axes[0].set_xlabel(\"Difference\")\n",
    "axes[0].set_ylabel(\"Density\")\n",
    "axes[0].legend()\n",
    "\n",
    "# B. Paired Scatter Plot\n",
    "axes[1].plot(pre, post, 'o', color='skyblue')\n",
    "axes[1].plot([pre.min(), pre.max()], [pre.min(), pre.max()],\n",
    "             'k--', label='No change')\n",
    "axes[1].set_xlabel(\"Pre measurement\")\n",
    "axes[1].set_ylabel(\"Post measurement\")\n",
    "axes[1].set_title(\"Paired Measurements (Before vs After)\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle(\"Paired t-test Results: t = \"\n",
    "             f\"{t_stat:.2f}, p = {p_value:.3f}\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92258de6-94f0-4c02-9f86-5a09f7d6b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.Simulate data and perform both Z-test and T-test, then compare the results using Python\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp, norm\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "# Parameters\n",
    "np.random.seed(1)\n",
    "pop_mean = 50\n",
    "pop_sigma = 5    # Suppose known for Z-test\n",
    "n_large = 100    # for Z-test (n>30)\n",
    "n_small = 20     # for T-test\n",
    "\n",
    "# Simulate large sample for Z-test\n",
    "data_large = np.random.normal(loc=pop_mean + 2, scale=pop_sigma, size=n_large)\n",
    "sample_mean_large = data_large.mean()\n",
    "z_manual = (sample_mean_large - pop_mean) / (pop_sigma / np.sqrt(n_large))\n",
    "z_stat, z_p = ztest(data_large, value=pop_mean)\n",
    "\n",
    "# Simulate small sample for T-test\n",
    "data_small = np.random.normal(loc=pop_mean + 2, scale=pop_sigma, size=n_small)\n",
    "t_stat, t_p = ttest_1samp(data_small, pop_mean)\n",
    "\n",
    "# Print results\n",
    "print(\"üîç Large sample Z-test (œÉ known):\")\n",
    "print(f\"  Sample mean = {sample_mean_large:.2f}\")\n",
    "print(f\"  Manual Z = {z_manual:.3f}, statsmodels Z = {z_stat:.3f}\")\n",
    "print(f\"  P-value = {z_p:.4f}\")\n",
    "\n",
    "print(\"\\nüîç Small sample T-test (œÉ unknown):\")\n",
    "print(f\"  Sample mean = {data_small.mean():.2f}\")\n",
    "print(f\"  t-statistic = {t_stat:.3f}\")\n",
    "print(f\"  P-value = {t_p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07842566-87d7-481f-8dc9-15c76660e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.Write a Python function to calculate the confidence interval for a sample mean and explain its significance?\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate mean and two-sided confidence interval for the mean.\n",
    "    Returns (mean, lower_bound, upper_bound).\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    n = len(data)\n",
    "    mean = data.mean()\n",
    "    sem = stats.sem(data)  # standard error of the mean\n",
    "\n",
    "    # Determine critical value: use t-distribution if n ‚â§ 30, else z\n",
    "    alpha = 1 - confidence\n",
    "    if n <= 30:\n",
    "        crit = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "    else:\n",
    "        crit = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    lower = mean - crit * sem\n",
    "    upper = mean + crit * sem\n",
    "    return mean, lower, upper\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=100, scale=15, size=40)\n",
    "mean, lo, hi = mean_confidence_interval(data, confidence=0.95)\n",
    "\n",
    "print(f\"Sample mean = {mean:.2f}\")\n",
    "print(f\"95% CI = [{lo:.2f}, {hi:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f91d2-5672-4472-af57-059e7bcfeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Write a Python program to calculate the margin of error for a given confidence level using sample data.\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def margin_of_error(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate the margin of error for the sample mean at the given confidence level.\n",
    "    Returns (margin, sample_mean).\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    n = len(data)\n",
    "    mean = data.mean()\n",
    "    sem = stats.sem(data)  # Sample standard error\n",
    "\n",
    "    alpha = 1 - confidence\n",
    "    # Use t-distribution if sample size small, otherwise z\n",
    "    if n <= 30:\n",
    "        crit = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "    else:\n",
    "        crit = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    moe = crit * sem\n",
    "    return mean, moe\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=100, scale=15, size=40)\n",
    "mean, moe = margin_of_error(data, confidence=0.95)\n",
    "\n",
    "print(f\"Sample mean = {mean:.2f}\")\n",
    "print(f\"Margin of Error (95% CI) = ¬±{moe:.2f}\")\n",
    "print(f\"Confidence interval: [{mean - moe:.2f}, {mean + moe:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618068fa-0ae0-4502-af8c-27a408c29289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def bayes_coin(observed_heads, n_flips, prior_fair=0.5, p_fair=0.5, p_biased=0.75):\n",
    "    \"\"\"\n",
    "    Bayesian update for coin fairness:\n",
    "      - observed_heads: number of heads observed\n",
    "      - n_flips: total coin flips\n",
    "      - prior_fair: P(H0) prior for fair coin\n",
    "      - p_fair: P(head|fair coin)\n",
    "      - p_biased: P(head|biased coin)\n",
    "    Returns posterior probabilities P(H0|D) and P(H1|D).\n",
    "    \"\"\"\n",
    "    prior_biased = 1 - prior_fair\n",
    "    \n",
    "    # Likelihoods\n",
    "    likelihood_fair = stats.binom.pmf(observed_heads, n_flips, p_fair)\n",
    "    likelihood_biased = stats.binom.pmf(observed_heads, n_flips, p_biased)\n",
    "    \n",
    "    # Marginal likelihood\n",
    "    marginal = (likelihood_fair * prior_fair +\n",
    "                likelihood_biased * prior_biased)\n",
    "    \n",
    "    # Compute posteriors using Bayes' theorem\n",
    "    post_fair = (likelihood_fair * prior_fair) / marginal\n",
    "    post_biased = (likelihood_biased * prior_biased) / marginal\n",
    "    \n",
    "    return post_fair, post_biased\n",
    "\n",
    "# Example usage\n",
    "observed_heads, n_flips = 8, 10\n",
    "post_fair, post_biased = bayes_coin(observed_heads, n_flips)\n",
    "\n",
    "print(f\"After {observed_heads}/{n_flips} heads:\")\n",
    "print(f\"Posterior P(fair)   = {post_fair:.3f}\")\n",
    "print(f\"Posterior P(biased) = {post_biased:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdac5b5-13ad-468a-8989-c7713c8a240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.Perform a Chi-square test for independence between two categorical variables in Python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# 1. Simulate categorical data (e.g., survey responses)\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "gender = np.random.choice(['Male', 'Female'], size=n, p=[0.5, 0.5])\n",
    "preference = np.random.choice(['Brand A', 'Brand B', 'Brand C'], size=n, p=[0.4, 0.4, 0.2])\n",
    "\n",
    "df = pd.DataFrame({'Gender': gender, 'Preference': preference})\n",
    "\n",
    "# 2. Create contingency table\n",
    "contingency = pd.crosstab(df['Gender'], df['Preference'])\n",
    "print(\"Contingency Table:\\n\", contingency, \"\\n\")\n",
    "\n",
    "# 3. Perform Chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "print(f\"Chi-square statistic = {chi2:.3f}\")\n",
    "print(f\"Degrees of freedom  = {dof}\")\n",
    "print(f\"P-value              = {p:.4f}\")\n",
    "print(\"Expected frequencies:\\n\", pd.DataFrame(expected, index=contingency.index, columns=contingency.columns), \"\\n\")\n",
    "\n",
    "# 4. Interpret the result\n",
    "alpha = 0.05\n",
    "if p < alpha:\n",
    "    print(\"‚Üí Reject H‚ÇÄ: There is a statistically significant association between Gender and Preference.\")\n",
    "else:\n",
    "    print(\"‚Üí Fail to reject H‚ÇÄ: No significant association detected between Gender and Preference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deceef4-34be-4d48-8ae3-3483b34de80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Simulate observed data (e.g. preferences by gender)\n",
    "observed = np.array([\n",
    "    [30, 10],  # e.g. Male: 30 Yes, 10 No\n",
    "    [20, 40]   # e.g. Female: 20 Yes, 40 No\n",
    "])\n",
    "df_obs = pd.DataFrame(observed, index=['Male','Female'], columns=['Yes','No'])\n",
    "print(\"Observed:\\n\", df_obs, \"\\n\")\n",
    "\n",
    "# Calculate expected frequencies\n",
    "chi2, p, dof, expected = chi2_contingency(observed, correction=False)\n",
    "\n",
    "df_exp = pd.DataFrame(expected, index=df_obs.index, columns=df_obs.columns)\n",
    "print(\"Expected (assuming independence):\\n\", df_exp, \"\\n\")\n",
    "\n",
    "# Display formula for one cell just to illustrate:\n",
    "# Expected[i,j] = (row_total_i * col_total_j) / grand_total\n",
    "i, j = 0, 0\n",
    "E_00 = (observed[i].sum() * observed[:,j].sum()) / observed.sum()\n",
    "print(f\"Example calc for cell [Male, Yes]: ({observed[i].sum()} * {observed[:,j].sum()}) \"\n",
    "      f\"/ {observed.sum()} = {E_00:.2f}\\n\")\n",
    "\n",
    "# Perform Chi-square test using these expected frequencies\n",
    "chi2_stat, p_val = np.sum((observed - expected)**2 / expected), p\n",
    "print(f\"Chi-square stat = {chi2_stat:.3f}, p-value = {p_val:.4f}, dof = {dof}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_val < alpha:\n",
    "    print(\"‚Üí Reject H‚ÇÄ: significant association found.\")\n",
    "else:\n",
    "    print(\"‚Üí Fail to reject H‚ÇÄ: no significant association detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0749d-e66f-47c5-9ff1-c42bf511097f",
   "metadata": {},
   "outputs": [],
   "source": [
    " #14.Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# 1. Observed counts (e.g., die rolls or categorical outcomes)\n",
    "observed = np.array([8, 10, 12, 11, 9, 10])\n",
    "labels = np.arange(1, len(observed) + 1)\n",
    "\n",
    "# 2. Expected counts under the null hypothesis (e.g., fair die ‚Üí uniform expected)\n",
    "expected = np.full_like(observed, fill_value=observed.sum() / observed.size)\n",
    "\n",
    "# 3. Perform the Chi-square goodness-of-fit test\n",
    "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
    "\n",
    "print(f\"Observed counts: {observed}\")\n",
    "print(f\"Expected counts: {expected}\")\n",
    "print(f\"Chi-square statistic = {chi2_stat:.3f}\")\n",
    "print(f\"P‚Äëvalue = {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"‚Üí Reject H‚ÇÄ: observed distribution deviates significantly from expected.\")\n",
    "else:\n",
    "    print(\"‚Üí Fail to reject H‚ÇÄ: no significant difference from expected distribution.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9152399-402b-497e-ac7a-9469f877685f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774befc-eef7-40a6-afee-67d1c1827315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2d1b1-548a-4229-9468-030c019bc2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee48118-d982-4e21-baf5-1456c4c7f4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de49bc-8fbb-4bf8-9a70-6c52b6e953cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9ae46-6ade-478f-9b10-ab7846e7d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb78dd6-1776-4873-9d55-92ac9b3f2e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ef5bc-fdc4-43fd-9a40-d5e873053af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394400f1-142a-43ed-9b38-1679d9656d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5191b-c3e9-45fb-beb1-b9990f7e8bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
